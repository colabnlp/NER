{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from pathlib import Path \n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "import random \n",
    "\n",
    "# fastai\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "# transformers\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import RobertaForTokenClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fastai version : 1.0.59\n",
      "transformers version : 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "import transformers\n",
    "print('fastai version :', fastai.__version__)\n",
    "print('transformers version :', transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### To pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def readdf(filename):\n",
    "    ''' read file to dataframe '''\n",
    "    f = open(filename)\n",
    "    data, sentence, label = [], [], []\n",
    "    sentence_idx = 0\n",
    "    for line in f:\n",
    "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
    "            if len(sentence) > 0:\n",
    "                for word, tag in zip(sentence, label):\n",
    "                    data.append( (word, tag, sentence_idx) )\n",
    "                sentence_idx += 1\n",
    "                sentence, label = [], []\n",
    "            continue\n",
    "        splits = line.split(' ')\n",
    "        sentence.append(splits[0])\n",
    "        label.append(splits[-1][:-1])\n",
    "\n",
    "    if len(sentence) > 0:\n",
    "        data.append((sentence, label))\n",
    "    return pd.DataFrame(data, columns=['word', 'tag', 'sentence_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def readdfsentences(filename):\n",
    "    df = readdf(filename)\n",
    "    \n",
    "    agg_func = lambda s: ' '.join(s[\"word\"].values)\n",
    "    sentences = df.groupby(\"sentence_idx\").apply(agg_func)\n",
    "    agg_func = lambda s: ' '.join(s[\"tag\"].values)\n",
    "    labels = df.groupby(\"sentence_idx\").apply(agg_func)\n",
    "    \n",
    "    df = pd.concat([sentences, labels], axis=1)\n",
    "    df.columns = ['sentences', 'labels']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>B-ORG O B-MISC O O O B-MISC O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>B-PER I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>BRUSSELS 1996-08-22</td>\n",
       "      <td>B-LOC O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>The European Commission said on Thursday it di...</td>\n",
       "      <td>O B-ORG I-ORG O O O O O O B-MISC O O O O O B-M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Germany 's representative to the European Unio...</td>\n",
       "      <td>B-LOC O O O O B-ORG I-ORG O O O B-PER I-PER O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      sentences  \\\n",
       "sentence_idx                                                      \n",
       "0.0            EU rejects German call to boycott British lamb .   \n",
       "1.0                                             Peter Blackburn   \n",
       "2.0                                         BRUSSELS 1996-08-22   \n",
       "3.0           The European Commission said on Thursday it di...   \n",
       "4.0           Germany 's representative to the European Unio...   \n",
       "\n",
       "                                                         labels  \n",
       "sentence_idx                                                     \n",
       "0.0                             B-ORG O B-MISC O O O B-MISC O O  \n",
       "1.0                                                 B-PER I-PER  \n",
       "2.0                                                     B-LOC O  \n",
       "3.0           O B-ORG I-ORG O O O O O O B-MISC O O O O O B-M...  \n",
       "4.0           B-LOC O O O O B-ORG I-ORG O O O B-PER I-PER O ...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = readdfsentences('NER_datasets/CONLL2003/train.txt')\n",
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14040, 2) (3249, 2) (3452, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRI...</td>\n",
       "      <td>O O B-LOC O O O O B-PER O O O O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Nadim Ladki</td>\n",
       "      <td>B-PER I-PER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>AL-AIN , United Arab Emirates 1996-12-06</td>\n",
       "      <td>B-LOC O B-LOC I-LOC I-LOC O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>Japan began the defence of their Asian Cup tit...</td>\n",
       "      <td>B-LOC O O O O O B-MISC I-MISC O O O O O O O B-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>But China saw their luck desert them in the se...</td>\n",
       "      <td>O B-LOC O O O O O O O O O O O O O O O O O O O ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      sentences  \\\n",
       "sentence_idx                                                      \n",
       "0.0           SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRI...   \n",
       "1.0                                                 Nadim Ladki   \n",
       "2.0                    AL-AIN , United Arab Emirates 1996-12-06   \n",
       "3.0           Japan began the defence of their Asian Cup tit...   \n",
       "4.0           But China saw their luck desert them in the se...   \n",
       "\n",
       "                                                         labels  \n",
       "sentence_idx                                                     \n",
       "0.0                             O O B-LOC O O O O B-PER O O O O  \n",
       "1.0                                                 B-PER I-PER  \n",
       "2.0                                 B-LOC O B-LOC I-LOC I-LOC O  \n",
       "3.0           B-LOC O O O O O B-MISC I-MISC O O O O O O O B-...  \n",
       "4.0           O B-LOC O O O O O O O O O O O O O O O O O O O ...  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_ROOT = 'NER_datasets/CONLL2003/'\n",
    "train_df = readdfsentences(DATA_ROOT + 'train.txt')\n",
    "valid_df = readdfsentences(DATA_ROOT + 'valid.txt')\n",
    "test_df = readdfsentences(DATA_ROOT + 'test.txt')\n",
    "print(train_df.shape, valid_df.shape, test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>labels</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>B-ORG O B-MISC O O O B-MISC O O</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>Peter Blackburn</td>\n",
       "      <td>B-PER I-PER</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>BRUSSELS 1996-08-22</td>\n",
       "      <td>B-LOC O</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>The European Commission said on Thursday it di...</td>\n",
       "      <td>O B-ORG I-ORG O O O O O O B-MISC O O O O O B-M...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>Germany 's representative to the European Unio...</td>\n",
       "      <td>B-LOC O O O O B-ORG I-ORG O O O B-PER I-PER O ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      sentences  \\\n",
       "sentence_idx                                                      \n",
       "0.0            EU rejects German call to boycott British lamb .   \n",
       "1.0                                             Peter Blackburn   \n",
       "2.0                                         BRUSSELS 1996-08-22   \n",
       "3.0           The European Commission said on Thursday it di...   \n",
       "4.0           Germany 's representative to the European Unio...   \n",
       "\n",
       "                                                         labels  valid  \n",
       "sentence_idx                                                            \n",
       "0.0                             B-ORG O B-MISC O O O B-MISC O O  False  \n",
       "1.0                                                 B-PER I-PER  False  \n",
       "2.0                                                     B-LOC O  False  \n",
       "3.0           O B-ORG I-ORG O O O O O O B-MISC O O O O O B-M...  False  \n",
       "4.0           B-LOC O O O O B-ORG I-ORG O O O B-PER I-PER O ...  False  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join train and valid dfsb\n",
    "train_df['valid'] = False\n",
    "valid_df['valid'] = True\n",
    "train_df = pd.concat([train_df, valid_df])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CLASSES = {\n",
    "    'roberta': (RobertaForTokenClassification, RobertaTokenizer, RobertaConfig)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "seed = 42\n",
    "use_fp16 = False\n",
    "bs = 16\n",
    "\n",
    "model_type = 'roberta'\n",
    "pretrained_model_name = 'roberta-base' # 'roberta-base-openai-detector'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['roberta-base', 'roberta-large', 'roberta-large-mnli', 'distilroberta-base', 'roberta-base-openai-detector', 'roberta-large-openai-detector'])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_class.pretrained_model_archive_map.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_all(seed_value):\n",
    "    random.seed(seed_value) # Python\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    \n",
    "    if torch.cuda.is_available(): \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TransformersBaseTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, pretrained_tokenizer: PreTrainedTokenizer, model_type = 'bert', **kwargs):\n",
    "        self._pretrained_tokenizer = pretrained_tokenizer\n",
    "        self.max_seq_len = pretrained_tokenizer.max_len\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        CLS = self._pretrained_tokenizer.cls_token\n",
    "        SEP = self._pretrained_tokenizer.sep_token\n",
    "        if self.model_type in ['roberta']:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t, add_prefix_space=True)[:self.max_seq_len - 2]\n",
    "        else:\n",
    "            tokens = self._pretrained_tokenizer.tokenize(t)[:self.max_seq_len - 2]\n",
    "        return [CLS] + tokens + [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transformer_tokenizer = tokenizer_class.from_pretrained(pretrained_model_name)\n",
    "transformer_base_tokenizer = TransformersBaseTokenizer(pretrained_tokenizer = transformer_tokenizer, model_type = model_type)\n",
    "fastai_tokenizer = Tokenizer(tok_func = transformer_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_file': {'roberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json',\n",
       "  'roberta-large': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json',\n",
       "  'roberta-large-mnli': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-vocab.json',\n",
       "  'distilroberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-vocab.json',\n",
       "  'roberta-base-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json',\n",
       "  'roberta-large-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json'},\n",
       " 'merges_file': {'roberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt',\n",
       "  'roberta-large': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt',\n",
       "  'roberta-large-mnli': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-merges.txt',\n",
       "  'distilroberta-base': 'https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-merges.txt',\n",
       "  'roberta-base-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt',\n",
       "  'roberta-large-openai-detector': 'https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt'}}"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_class.pretrained_vocab_files_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TransformersVocab(Vocab):\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer):\n",
    "        super(TransformersVocab, self).__init__(itos = [])\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return self.tokenizer.convert_tokens_to_ids(t)\n",
    "        #return self.tokenizer.encode(t)\n",
    "\n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(self.tokenizer.convert_ids_to_tokens(nums)) if sep is not None else self.tokenizer.convert_ids_to_tokens(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "transformer_vocab =  TransformersVocab(tokenizer = transformer_tokenizer)\n",
    "numericalize_processor = NumericalizeProcessor(vocab=transformer_vocab)\n",
    "\n",
    "tokenize_processor = TokenizeProcessor(tokenizer=fastai_tokenizer, include_bos=False, include_eos=False)\n",
    "\n",
    "transformer_processor = [tokenize_processor, numericalize_processor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pad_first = bool(model_type in ['xlnet'])\n",
    "pad_idx = transformer_tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LabelTokenizer(BaseTokenizer):\n",
    "    \"\"\"Wrapper around PreTrainedTokenizer to be compatible with fast.ai\"\"\"\n",
    "    def __init__(self, labels, max_seq_len=999, **kwargs):\n",
    "        self.labels = labels\n",
    "        self.max_seq_len = max_seq_len\n",
    "\n",
    "    def __call__(self, *args, **kwargs): \n",
    "        return self\n",
    "\n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        \"\"\"Limits the maximum sequence length and add the spesial tokens\"\"\"\n",
    "        return self.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = [\"O\", \"B-MISC\", \"I-MISC\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"[CLS]\", \"[SEP]\", \"X\"]\n",
    "\n",
    "label_base_tokenizer = LabelTokenizer(labels)\n",
    "label_tokenizer = Tokenizer(tok_func = label_base_tokenizer, pre_rules=[], post_rules=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class LabelVocab(Vocab):\n",
    "    def __init__(self, labels):\n",
    "        super().__init__(itos = [])\n",
    "        self.int2str = labels\n",
    "        self.str2int = { s:i for i,s in enumerate(labels) }\n",
    "    \n",
    "    def numericalize(self, t:Collection[str]) -> List[int]:\n",
    "        \"Convert a list of tokens `t` to their ids.\"\n",
    "        return list(map(lambda i: self.str2int[i], t))\n",
    "    \n",
    "    def textify(self, nums:Collection[int], sep=' ') -> List[str]:\n",
    "        \"Convert a list of `nums` to their tokens.\"\n",
    "        nums = np.array(nums).tolist()\n",
    "        return sep.join(list(map(lambda i: self.int2str[i], nums)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def LabelNumericalizeProcessor(ds, **kwargs):\n",
    "    return NumericalizeProcessor(ds, vocab=LabelVocab(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def LabelTokenizeProcessor(ds, **kwargs):\n",
    "    return TokenizeProcessor(ds, tokenizer=label_tokenizer, include_bos=False, include_eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class TextLabelList(TextList):\n",
    "    _processor = [LabelTokenizeProcessor, LabelNumericalizeProcessor]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Databunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_collate(samples, pad_idx=1, pad_first=True, backwards=False):\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    samples = to_data(samples)\n",
    "    max_len_x,max_len_y = max([len(s[0]) for s in samples]),max([len(s[1]) for s in samples])\n",
    "    res_x = torch.zeros(len(samples), max_len_x).long() + pad_idx\n",
    "    res_y = torch.zeros(len(samples), max_len_y).long() + pad_idx\n",
    "    if backwards: pad_first = not pad_first\n",
    "    for i,s in enumerate(samples):\n",
    "        if pad_first: \n",
    "            res_x[i,-len(s[0]):],res_y[i,-len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "        else:         \n",
    "            res_x[i,:len(s[0]):],res_y[i,:len(s[1]):] = LongTensor(s[0]),LongTensor(s[1])\n",
    "    if backwards: res_x,res_y = res_x.flip(1),res_y.flip(1)\n",
    "    return res_x,res_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataBunch(TextDataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training an RNN classifier.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs:int=32, val_bs:int=None, pad_idx=1,\n",
    "               dl_tfms=None, pad_first=False, device:torch.device=None, no_check:bool=False, backwards:bool=False, **dl_kwargs) -> DataBunch:\n",
    "        \"Function that transform the `datasets` in a `DataBunch` for classification. Passes `**dl_kwargs` on to `DataLoader()`\"\n",
    "        \n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "        val_bs = ifnone(val_bs, bs)\n",
    "        collate_fn = partial(seq2seq_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=backwards)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **dl_kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=val_bs, sampler=sampler, **dl_kwargs))\n",
    "        return cls(*dataloaders, path=path, device=device, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqTextList(TextList):\n",
    "    _bunch = Seq2SeqDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LabelLists;\n",
       "\n",
       "Train: LabelList (14040 items)\n",
       "x: Seq2SeqTextList\n",
       "<s> ĠEU Ġrejects ĠGerman Ġcall Ġto Ġboycott ĠBritish Ġlamb Ġ. </s>,<s> ĠPeter ĠBlackburn </s>,<s> ĠBR USS ELS Ġ1996 - 08 - 22 </s>,<s> ĠThe ĠEuropean ĠCommission Ġsaid Ġon ĠThursday Ġit Ġdisagreed Ġwith ĠGerman Ġadvice Ġto Ġconsumers Ġto Ġshun ĠBritish Ġlamb Ġuntil Ġscientists Ġdetermine Ġwhether Ġmad Ġcow Ġdisease Ġcan Ġbe Ġtransmitted Ġto Ġsheep Ġ. </s>,<s> ĠGermany Ġ' s Ġrepresentative Ġto Ġthe ĠEuropean ĠUnion Ġ' s Ġveterinary Ġcommittee ĠWerner ĠZ wing mann Ġsaid Ġon ĠWednesday Ġconsumers Ġshould Ġbuy Ġsheep meat Ġfrom Ġcountries Ġother Ġthan ĠBritain Ġuntil Ġthe Ġscientific Ġadvice Ġwas Ġclearer Ġ. </s>\n",
       "y: TextLabelList\n",
       "O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X,O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X,O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X,O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X,O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (3249 items)\n",
       "x: Seq2SeqTextList\n",
       "<s> ĠCR ICK ET Ġ- ĠLE IC EST ERS HI RE ĠTA KE ĠOVER ĠAT ĠTOP ĠAFTER ĠIN NING S ĠV ICT ORY Ġ. </s>,<s> ĠL ONDON Ġ1996 - 08 - 30 </s>,<s> ĠWest ĠIndian Ġall - rounder ĠPhil ĠSimmons Ġtook Ġfour Ġfor Ġ38 Ġon ĠFriday Ġas ĠLe ices ters hire Ġbeat ĠSomerset Ġby Ġan Ġinnings Ġand Ġ39 Ġruns Ġin Ġtwo Ġdays Ġto Ġtake Ġover Ġat Ġthe Ġhead Ġof Ġthe Ġcounty Ġchampionship Ġ. </s>,<s> ĠTheir Ġstay Ġon Ġtop Ġ, Ġthough Ġ, Ġmay Ġbe Ġshort - lived Ġas Ġtitle Ġrivals ĠEssex Ġ, ĠDer bys hire Ġand ĠSurrey Ġall Ġclosed Ġin Ġon Ġvictory Ġwhile ĠKent Ġmade Ġup Ġfor Ġlost Ġtime Ġin Ġtheir Ġrain - affected Ġmatch Ġagainst ĠNottingham shire Ġ. </s>,<s> ĠAfter Ġbowling ĠSomerset Ġout Ġfor Ġ83 Ġon Ġthe Ġopening Ġmorning Ġat ĠGrace ĠRoad Ġ, ĠLe ices ters hire Ġextended Ġtheir Ġfirst Ġinnings Ġby Ġ94 Ġruns Ġbefore Ġbeing Ġbow led Ġout Ġfor Ġ296 Ġwith ĠEngland Ġdiscard ĠAndy ĠC add ick Ġtaking Ġthree Ġfor Ġ83 Ġ. </s>\n",
       "y: TextLabelList\n",
       "O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X,O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X,O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X,O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X,O B-MISC I-MISC B-PER I-PER B-ORG I-ORG B-LOC I-LOC [CLS] [SEP] X\n",
       "Path: .;\n",
       "\n",
       "Test: LabelList (3452 items)\n",
       "x: Seq2SeqTextList\n",
       "<s> ĠSO CC ER Ġ- ĠJ AP AN ĠGET ĠL UCK Y ĠWIN Ġ, ĠCH INA ĠIN ĠSUR PR ISE ĠDE FE AT Ġ. ĠO ĠO ĠB - LOC ĠO ĠO ĠO ĠO ĠB - PER ĠO ĠO ĠO ĠO </s>,<s> ĠNad im ĠLad ki ĠB - PER ĠI - PER </s>,<s> ĠAL - AIN Ġ, ĠUnited ĠArab ĠEmirates Ġ1996 - 12 - 06 ĠB - LOC ĠO ĠB - LOC ĠI - LOC ĠI - LOC ĠO </s>,<s> ĠJapan Ġbegan Ġthe Ġdefence Ġof Ġtheir ĠAsian ĠCup Ġtitle Ġwith Ġa Ġlucky Ġ2 - 1 Ġwin Ġagainst ĠSyria Ġin Ġa ĠGroup ĠC Ġchampionship Ġmatch Ġon ĠFriday Ġ. ĠB - LOC ĠO ĠO ĠO ĠO ĠO ĠB - M ISC ĠI - M ISC ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠB - LOC ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO </s>,<s> ĠBut ĠChina Ġsaw Ġtheir Ġluck Ġdesert Ġthem Ġin Ġthe Ġsecond Ġmatch Ġof Ġthe Ġgroup Ġ, Ġcrashing Ġto Ġa Ġsurprise Ġ2 - 0 Ġdefeat Ġto Ġnewcomers ĠUzbek istan Ġ. ĠO ĠB - LOC ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠO ĠB - LOC ĠO </s>\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: ."
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = (Seq2SeqTextList.from_df(train_df, cols='sentences', processor=transformer_processor)\n",
    "       .split_from_df(col='valid')\n",
    "       .label_from_df(cols='labels', label_cls=TextLabelList)\n",
    "       .add_test(test_df))\n",
    "src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
