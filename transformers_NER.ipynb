{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from torch.utils import data\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from seqeval.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/29/2019 22:43:06 - INFO - transformers.file_utils -   PyTorch version 1.3.1 available.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForTokenClassification\n",
    "from transformers import BertTokenizer, AdamW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNIQUE_LABELS = {'X', '[CLS]', '[SEP]'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unicode(text):\n",
    "    \"\"\"Converts `text` to Unicode (if it's not already), assuming utf-8 input.\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        return text\n",
    "    elif isinstance(text, bytes):\n",
    "        return text.decode(\"utf-8\", \"ignore\")\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported string type: %s\" % (type(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text, label=None, segment_ids=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "        Args:\n",
    "          guid: Unique id for the example.\n",
    "          text_a: string. The untokenized text of the first sequence. For single\n",
    "            sequence tasks, only this sequence must be specified.\n",
    "          label: (Optional) string. The label of the example. This should be\n",
    "            specified for train and dev examples, but not for test examples.\n",
    "        \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text = text\n",
    "        self.label = label\n",
    "        self.segment_ids = segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(filename):\n",
    "    '''\n",
    "    read file\n",
    "    '''\n",
    "    f = open(filename)\n",
    "    data = []\n",
    "    sentence = []\n",
    "    label = []\n",
    "    for line in f:\n",
    "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
    "            if len(sentence) > 0:\n",
    "                data.append((sentence, label))\n",
    "                sentence = []\n",
    "                label = []\n",
    "            continue\n",
    "        splits = line.split(' ')\n",
    "        sentence.append(splits[0])\n",
    "        label.append(splits[-1][:-1])\n",
    "\n",
    "    if len(sentence) > 0:\n",
    "        data.append((sentence, label))\n",
    "        sentence = []\n",
    "        label = []\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.'], ['O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O'])\n"
     ]
    }
   ],
   "source": [
    "test_data = readfile('./NER_datasets/CONLL2003/test.txt')\n",
    "print(test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor(object):\n",
    "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def get_labels(self):\n",
    "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @classmethod\n",
    "    def _read_tsv(cls, input_file, quotechar=None):\n",
    "        \"\"\"Reads a tab separated value file.\"\"\"\n",
    "        return readfile(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NerProcessor(DataProcessor):\n",
    "    \"\"\"Processor for the CoNLL-2003 data set.\"\"\"\n",
    "\n",
    "    def get_train_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(self._read_tsv(os.path.join(data_dir, \"train.txt\")), \"train\")\n",
    "\n",
    "    def get_dev_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"valid.txt\")),\n",
    "            \"dev\")\n",
    "\n",
    "    def get_test_examples(self, data_dir):\n",
    "        \"\"\"See base class.\"\"\"\n",
    "        return self._create_examples(\n",
    "            self._read_tsv(os.path.join(data_dir, \"test.txt\")),\n",
    "            \"test\")\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [\"O\", \"B-MISC\", \"I-MISC\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\",\n",
    "                \"[CLS]\", \"[SEP]\", \"X\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_examples(lines, set_type):\n",
    "        examples = []\n",
    "        for i, (sentence, label) in enumerate(lines):\n",
    "            guid = \"%s-%s\" % (set_type, i)\n",
    "            text_a = ' '.join(sentence)\n",
    "            label = label\n",
    "            examples.append(InputExample(guid=guid, text=text_a, label=label))\n",
    "        return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = NerProcessor().get_train_examples('./NER_datasets/CONLL2003/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train-101', None)\n",
      "('He will be replaced by Eliahu Ben-Elissar , a former Israeli envoy to Egypt and right-wing Likud party politician .', ['O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'B-LOC', 'O', 'O', 'B-ORG', 'O', 'O', 'O'])\n"
     ]
    }
   ],
   "source": [
    "x = train_examples[101]\n",
    "print((x.guid, x.segment_ids))\n",
    "print((x.text, x.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataSet(data.Dataset):\n",
    "    def __init__(self, data_list, tokenizer, label_map, max_len):\n",
    "        self.max_len = max_len\n",
    "        self.label_map = label_map\n",
    "        self.data_list = data_list\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_example = self.data_list[idx]\n",
    "        text = input_example.text\n",
    "        label = input_example.label\n",
    "        word_tokens = ['[CLS]']\n",
    "        label_list = ['[CLS]']\n",
    "        label_mask = [0]  # value in (0, 1) - 0 signifies invalid token\n",
    "\n",
    "        input_ids = [self.tokenizer.convert_tokens_to_ids('[CLS]')]\n",
    "        label_ids = [self.label_map['[CLS]']]\n",
    "\n",
    "        # iterate over individual tokens and their labels\n",
    "        for word, label in zip(text.split(), label):\n",
    "            tokenized_word = self.tokenizer.tokenize(word)\n",
    "\n",
    "            for token in tokenized_word:\n",
    "                word_tokens.append(token)\n",
    "                input_ids.append(self.tokenizer.convert_tokens_to_ids(token))\n",
    "\n",
    "            label_list.append(label)\n",
    "            label_ids.append(self.label_map[label])\n",
    "            label_mask.append(1)\n",
    "            # len(tokenized_word) > 1 only if it splits word in between, in which case\n",
    "            # the first token gets assigned NER tag and the remaining ones get assigned\n",
    "            # X\n",
    "            for i in range(1, len(tokenized_word)):\n",
    "                label_list.append('X')\n",
    "                label_ids.append(self.label_map['X'])\n",
    "                label_mask.append(0)\n",
    "\n",
    "        assert len(word_tokens) == len(label_list) == len(input_ids) == len(label_ids) == len(\n",
    "            label_mask)\n",
    "\n",
    "        if len(word_tokens) >= self.max_len:\n",
    "            word_tokens = word_tokens[:(self.max_len - 1)]\n",
    "            label_list = label_list[:(self.max_len - 1)]\n",
    "            input_ids = input_ids[:(self.max_len - 1)]\n",
    "            label_ids = label_ids[:(self.max_len - 1)]\n",
    "            label_mask = label_mask[:(self.max_len - 1)]\n",
    "\n",
    "        assert len(word_tokens) < self.max_len, len(word_tokens)\n",
    "\n",
    "        word_tokens.append('[SEP]')\n",
    "        label_list.append('[SEP]')\n",
    "        input_ids.append(self.tokenizer.convert_tokens_to_ids('[SEP]'))\n",
    "        label_ids.append(self.label_map['[SEP]'])\n",
    "        label_mask.append(0)\n",
    "\n",
    "        assert len(word_tokens) == len(label_list) == len(input_ids) == len(label_ids) == len(\n",
    "            label_mask)\n",
    "\n",
    "        sentence_id = [0 for _ in input_ids]\n",
    "        attention_mask = [1 for _ in input_ids]\n",
    "\n",
    "        while len(input_ids) < self.max_len:\n",
    "            input_ids.append(0)\n",
    "            label_ids.append(self.label_map['X'])\n",
    "            attention_mask.append(0)\n",
    "            sentence_id.append(0)\n",
    "            label_mask.append(0)\n",
    "\n",
    "        assert len(word_tokens) == len(label_list)\n",
    "        assert len(input_ids) == len(label_ids) == len(attention_mask) == len(sentence_id) == len(\n",
    "            label_mask) == self.max_len, len(input_ids)\n",
    "        # return word_tokens, label_list,\n",
    "        return torch.LongTensor(input_ids), torch.LongTensor(label_ids), torch.LongTensor(\n",
    "            attention_mask), torch.LongTensor(sentence_id), torch.BoolTensor(label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O': 0, 'B-MISC': 1, 'I-MISC': 2, 'B-PER': 3, 'I-PER': 4, 'B-ORG': 5, 'I-ORG': 6, 'B-LOC': 7, 'I-LOC': 8, '[CLS]': 9, '[SEP]': 10, 'X': 11, '': 11}\n"
     ]
    }
   ],
   "source": [
    "ner_processor = NerProcessor()\n",
    "\n",
    "tags_vals = ner_processor.get_labels()\n",
    "label_map = {}\n",
    "\n",
    "for (i, label) in enumerate(tags_vals):\n",
    "    label_map[label] = i\n",
    "    \n",
    "label_map[''] = 11 # same as 'X'\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = ner_processor.get_train_examples('./NER_datasets/CONLL2003/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/29/2019 22:43:09 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /home/dominykas/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101, 9)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids('[CLS]'), label_map['[CLS]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataSet(data_list=train_examples, tokenizer=tokenizer, label_map=label_map, max_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][4]\n",
    "# returns: (text, label, mask, idk, label_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32),\n",
       " tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0], dtype=torch.int32))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference between mask and label_mask\n",
    "train_dataset[0][2].type(torch.int), train_dataset[0][4].type(torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoNLLClassifier(BertForTokenClassification):\n",
    "    def forward(self, input_ids, attention_mask=None, token_type_ids=None,\n",
    "                position_ids=None, head_mask=None, labels=None, label_masks=None):\n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            position_ids=position_ids,\n",
    "                            head_mask=head_mask)\n",
    "\n",
    "        sequence_output = outputs[0]  # (b, MAX_LEN, 768)\n",
    "\n",
    "        token_reprs = [embedding[mask] for mask, embedding in zip(label_masks, sequence_output)]\n",
    "        token_reprs = pad_sequence(sequences=token_reprs, batch_first=True,\n",
    "                                   padding_value=-1)  # (b, local_max_len, 768)\n",
    "        sequence_output = self.dropout(token_reprs)\n",
    "        logits = self.classifier(sequence_output)  # (b, local_max_len, num_labels)\n",
    "\n",
    "        outputs = (logits,)\n",
    "        if labels is not None:\n",
    "            labels = [label[mask] for mask, label in zip(label_masks, labels)]\n",
    "            labels = pad_sequence(labels, batch_first=True, padding_value=-1)  # (b, local_max_len)\n",
    "            loss_fct = CrossEntropyLoss(ignore_index=-1, reduction='sum')\n",
    "            mask = labels != -1\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            loss /= mask.float().sum()\n",
    "            outputs = (loss, logits, labels)\n",
    "\n",
    "        return outputs  # (loss), scores, (hidden_states), (attentions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples = ner_processor.get_train_examples('./NER_datasets/CONLL2003/')\n",
    "val_examples = ner_processor.get_dev_examples('./NER_datasets/CONLL2003/')\n",
    "test_examples = ner_processor.get_test_examples('./NER_datasets/CONLL2003/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NERDataSet(train_examples, tokenizer, label_map, max_len=128)\n",
    "eval_dataset = NERDataSet(val_examples, tokenizer, label_map, max_len=128)\n",
    "test_dataset = NERDataSet(test_examples, tokenizer, label_map, max_len=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "train_iter = data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True,  num_workers=4)\n",
    "eval_iter =  data.DataLoader(dataset=eval_dataset,  batch_size=bs, shuffle=False, num_workers=4)\n",
    "test_iter =  data.DataLoader(dataset=test_dataset,  batch_size=bs, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/29/2019 22:43:17 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /home/dominykas/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.d7a3af18ce3a2ab7c0f48f04dc8daff45ed9a3ed333b9e9a79d012a0dedf87a6\n",
      "11/29/2019 22:43:17 - INFO - transformers.configuration_utils -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 13,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "11/29/2019 22:43:18 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /home/dominykas/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "11/29/2019 22:43:19 - INFO - transformers.modeling_utils -   Weights of CoNLLClassifier not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "11/29/2019 22:43:19 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in CoNLLClassifier: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    }
   ],
   "source": [
    "model = CoNLLClassifier.from_pretrained(\"bert-base-cased\", num_labels=len(label_map)).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_train_optimization_steps = int(len(train_examples) / bs) * num_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_FINETUNING = True\n",
    "lr = 3e-5\n",
    "\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = int(0.1 * num_train_optimization_steps)\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "# scheduler = WarmupLinearSchedule(optimizer, warmup_steps=warmup_steps, t_total=num_train_optimization_steps)\n",
    "scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/29/2019 22:47:21 - INFO - __main__ -   starting to train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4336ff55b4424dba6fdf406b285b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5, style=ProgressStyle(description_width='initialâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8ee723053284325b8f5750637a70889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=878), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/29/2019 23:37:08 - INFO - __main__ -   Train loss: 0.11004682384714577\n",
      "11/29/2019 23:37:08 - INFO - __main__ -   starting to evaluate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137667cbd6e04e809347f525cb6ea7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=204), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/29/2019 23:40:23 - INFO - __main__ -   Validation loss: 0.045760134218189884\n",
      "11/29/2019 23:40:23 - INFO - __main__ -   Seq eval accuracy: 0.9886795393877988\n",
      "11/29/2019 23:40:24 - INFO - __main__ -   F1-Score: 0.9304035424847524\n",
      "11/29/2019 23:40:24 - INFO - __main__ -   Classification report: -- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/29/2019 23:40:24 - INFO - __main__ -              precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.93      0.88      0.91      1341\n",
      "      PER       0.92      0.99      0.95      1836\n",
      "      LOC       0.96      0.95      0.96      1837\n",
      "     MISC       0.84      0.89      0.87       922\n",
      "        X       0.00      0.00      0.00         1\n",
      "\n",
      "micro avg       0.92      0.94      0.93      5937\n",
      "macro avg       0.92      0.94      0.93      5937\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e0352816f04e9f968455c1b52d5805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=878), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 00:29:53 - INFO - __main__ -   Train loss: 0.026279549470812014\n",
      "11/30/2019 00:29:53 - INFO - __main__ -   starting to evaluate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437580573ac8440ab652d93e49dc2f90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=204), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 00:33:08 - INFO - __main__ -   Validation loss: 0.04150540274585022\n",
      "11/30/2019 00:33:08 - INFO - __main__ -   Seq eval accuracy: 0.9905890146717846\n",
      "11/30/2019 00:33:08 - INFO - __main__ -   F1-Score: 0.9439126784214944\n",
      "11/30/2019 00:33:08 - INFO - __main__ -   Classification report: -- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 00:33:09 - INFO - __main__ -              precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.92      0.92      0.92      1341\n",
      "      PER       0.97      0.97      0.97      1836\n",
      "      LOC       0.96      0.96      0.96      1837\n",
      "     MISC       0.88      0.91      0.89       922\n",
      "        X       0.00      0.00      0.00         1\n",
      "\n",
      "micro avg       0.94      0.95      0.94      5937\n",
      "macro avg       0.94      0.95      0.94      5937\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d5f48ffaeb4caab5562d8312dfccb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=878), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 01:22:29 - INFO - __main__ -   Train loss: 0.014622718369912309\n",
      "11/30/2019 01:22:29 - INFO - __main__ -   starting to evaluate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df78cdf13a6345d7b774178944ae1d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=204), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 01:25:44 - INFO - __main__ -   Validation loss: 0.04302565876666146\n",
      "11/30/2019 01:25:44 - INFO - __main__ -   Seq eval accuracy: 0.9907059213218246\n",
      "11/30/2019 01:25:44 - INFO - __main__ -   F1-Score: 0.9428595331715887\n",
      "11/30/2019 01:25:44 - INFO - __main__ -   Classification report: -- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 01:25:45 - INFO - __main__ -              precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.90      0.93      0.91      1341\n",
      "      PER       0.97      0.98      0.97      1836\n",
      "      LOC       0.97      0.96      0.96      1837\n",
      "     MISC       0.87      0.90      0.89       922\n",
      "        X       0.00      0.00      0.00         1\n",
      "\n",
      "micro avg       0.94      0.95      0.94      5937\n",
      "macro avg       0.94      0.95      0.94      5937\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbaacf93f8c641ad8ef6f04a6939a007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=878), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 02:15:01 - INFO - __main__ -   Train loss: 0.008680306672296807\n",
      "11/30/2019 02:15:01 - INFO - __main__ -   starting to evaluate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac805580cd31486da015a5935e11c6ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=204), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 02:18:17 - INFO - __main__ -   Validation loss: 0.054337821371054994\n",
      "11/30/2019 02:18:17 - INFO - __main__ -   Seq eval accuracy: 0.9902188102799915\n",
      "11/30/2019 02:18:17 - INFO - __main__ -   F1-Score: 0.9447101266884805\n",
      "11/30/2019 02:18:17 - INFO - __main__ -   Classification report: -- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 02:18:17 - INFO - __main__ -              precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.87      0.95      0.91      1341\n",
      "      PER       0.97      0.97      0.97      1836\n",
      "      LOC       0.98      0.95      0.97      1837\n",
      "     MISC       0.92      0.90      0.91       922\n",
      "        X       0.00      0.00      0.00         1\n",
      "\n",
      "micro avg       0.94      0.95      0.94      5937\n",
      "macro avg       0.94      0.95      0.94      5937\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3071590620544ddaa2ef9679897e4304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=878), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 03:07:33 - INFO - __main__ -   Train loss: 0.006678770585474213\n",
      "11/30/2019 03:07:33 - INFO - __main__ -   starting to evaluate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1890b06945b545929390956dc28905b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=204), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 03:10:48 - INFO - __main__ -   Validation loss: 0.055189460339765815\n",
      "11/30/2019 03:10:48 - INFO - __main__ -   Seq eval accuracy: 0.9903162324883581\n",
      "11/30/2019 03:10:48 - INFO - __main__ -   F1-Score: 0.944258453297623\n",
      "11/30/2019 03:10:48 - INFO - __main__ -   Classification report: -- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 03:10:48 - INFO - __main__ -              precision    recall  f1-score   support\n",
      "\n",
      "      ORG       0.91      0.93      0.92      1341\n",
      "      PER       0.97      0.98      0.97      1836\n",
      "      LOC       0.96      0.97      0.96      1837\n",
      "     MISC       0.88      0.90      0.89       922\n",
      "        X       0.00      0.00      0.00         1\n",
      "\n",
      "micro avg       0.94      0.95      0.94      5937\n",
      "macro avg       0.94      0.95      0.94      5937\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(train_iter, eval_iter, model, optimizer, scheduler, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 03:10:48 - INFO - __main__ -   starting to evaluate\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68317836b044cc1810f26892ba14c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=216), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 03:14:16 - INFO - __main__ -   Validation loss: 0.16370227087335715\n",
      "11/30/2019 03:14:16 - INFO - __main__ -   Seq eval accuracy: 0.9806967274920826\n",
      "11/30/2019 03:14:16 - INFO - __main__ -   F1-Score: 0.90792928408892\n",
      "11/30/2019 03:14:16 - INFO - __main__ -   Classification report: -- \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/30/2019 03:14:16 - INFO - __main__ -              precision    recall  f1-score   support\n",
      "\n",
      "     MISC       0.77      0.83      0.80       702\n",
      "      ORG       0.88      0.91      0.89      1661\n",
      "      PER       0.96      0.96      0.96      1615\n",
      "      LOC       0.92      0.93      0.92      1666\n",
      "        X       0.00      0.00      0.00         1\n",
      "\n",
      "micro avg       0.90      0.92      0.91      5645\n",
      "macro avg       0.90      0.92      0.91      5645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval(test_iter, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, eval_iter, model, optimizer, scheduler, num_epochs, device='cuda'):\n",
    "    logger.info(\"starting to train\")\n",
    "    max_grad_norm = 1.0  # should be a flag\n",
    "    for _ in trange(num_epochs, desc=\"Epoch\"):\n",
    "        # TRAIN loop\n",
    "        model = model.train()\n",
    "        tr_loss = 0\n",
    "        nb_tr_steps = 0\n",
    "        for step, batch in enumerate(tqdm(train_iter)):\n",
    "            # add batch to gpu\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            b_input_ids, b_labels, b_input_mask, b_token_type_ids, b_label_masks = batch\n",
    "            # forward pass\n",
    "            loss, logits, labels = model(b_input_ids, token_type_ids=b_token_type_ids,\n",
    "                                         attention_mask=b_input_mask, labels=b_labels,\n",
    "                                         label_masks=b_label_masks)\n",
    "            # backward pass\n",
    "            loss.backward()\n",
    "            # track train loss\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_steps += 1\n",
    "            # gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "#             scheduler.step()\n",
    "            model.zero_grad()\n",
    "        # print train loss per epoch\n",
    "        logger.info(\"Train loss: {}\".format(tr_loss / nb_tr_steps))\n",
    "        eval(eval_iter, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(iter_data, model, device='cuda'):\n",
    "    logger.info(\"starting to evaluate\")\n",
    "    model = model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps = 0\n",
    "    predictions, true_labels = [], []\n",
    "    for batch in tqdm(iter_data):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        b_input_ids, b_labels, b_input_mask, b_token_type_ids, b_label_masks = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            tmp_eval_loss, logits, reduced_labels = model(b_input_ids,\n",
    "                                                          token_type_ids=b_token_type_ids,\n",
    "                                                          attention_mask=b_input_mask,\n",
    "                                                          labels=b_labels,\n",
    "                                                          label_masks=b_label_masks)\n",
    "\n",
    "        logits = torch.argmax(F.log_softmax(logits, dim=2), dim=2)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        reduced_labels = reduced_labels.to('cpu').numpy()\n",
    "\n",
    "        labels_to_append = []\n",
    "        predictions_to_append = []\n",
    "\n",
    "        for prediction, r_label in zip(logits, reduced_labels):\n",
    "            preds = []\n",
    "            labels = []\n",
    "            for pred, lab in zip(prediction, r_label):\n",
    "                if lab.item() == -1:  # masked label; -1 means do not collect this label\n",
    "                    continue\n",
    "                preds.append(pred)\n",
    "                labels.append(lab)\n",
    "            predictions_to_append.append(preds)\n",
    "            labels_to_append.append(labels)\n",
    "\n",
    "        predictions.extend(predictions_to_append)\n",
    "        true_labels.append(labels_to_append)\n",
    "\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    logger.info(\"Validation loss: {}\".format(eval_loss))\n",
    "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
    "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    logger.info(\"Seq eval accuracy: {}\".format(accuracy_score(valid_tags, pred_tags)))\n",
    "    logger.info(\"F1-Score: {}\".format(f1_score(valid_tags, pred_tags)))\n",
    "    logger.info(\"Classification report: -- \")\n",
    "    logger.info(classification_report(valid_tags, pred_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
